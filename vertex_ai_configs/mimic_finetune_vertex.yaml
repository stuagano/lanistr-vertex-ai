# Copyright 2024 Google LLC.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Vertex AI Configuration for MIMIC-IV Fine-tuning
# This config uses Google Cloud Storage paths for data and outputs

seed: 2022

# number of samples in training data to randomly subsample if greater than 0
sub_samples: 0

do_train: true
do_test: true

dataset_name: mimic-iv
task: finetune

# modalities presense
image: true
text: true
tab: false
time: true

# Fine-tuning settings
finetune_initialize_from: gs://your-bucket/lanistr-output/mimic_pretrain/checkpoints/latest.pt
finetune_initialize_from_epoch: 0

image_size: 224
image_crop: 224
mask_patch_size: 16
model_patch_size: 16
image_masking_ratio: 0.5

# GCS paths for Vertex AI
root_data_dir: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/physionet.org/files
image_data_dir: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/physionet.org/files/mimic-cxr-jpg/2.0.0
task_data_dir: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/in-hospital-mortality
unimodal_data_dir: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/in-hospital-mortality/unimodal_data
preprocessed_data_dir: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/
normalizer_file: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/normalizer.csv
discretizer_config_path: gs://your-bucket/lanistr-data/MIMIC-IV-V2.2/discretizer_config.json

# GCS output directory
output_dir: gs://your-bucket/lanistr-output/mimic_finetune
experiment_name: mimic_finetune

test_ratio: 0.2

train_batch_size: 64
eval_batch_size: 64
test_batch_size: 64

scheduler:
  num_epochs: 20
  warmup_epochs: 2

optimizer:
  learning_rate: 0.00001
  weight_decay: 0.01
  clip_value: 1.0

# Loss weights for fine-tuning
lambda_mim: 0.5
lambda_mlm: 0.5
lambda_mtm: 0.05
lambda_mmm: 0.5
lambda_classification: 1.0

# Multimodal fusion encoder
mm_encoder_trainable: true
mm_hidden_dim: 2048
mm_output_dim: 2048

# Classification head
num_classes: 2
classification_dropout: 0.1

# simsiam pretraining projector and predictor
projection_type: SimSiam
predictor_hidden_dim: 512
predictor_out_dim: 2048

# unimodal encoders projection dim
projection_dim: 768

# text encoder
text_encoder_name: bert-base-uncased
text_encoder_pretrained: true
text_encoder_trainable: false  # Freeze during fine-tuning
text_embedding_dim: 768
max_token_length: 512
mlm_probability: 0.15

# image encoder
image_encoder_name: google/vit-base-patch16-224
image_encoder_pretrained: true
image_encoder_trainable: false  # Freeze during fine-tuning
image_embedding_dim: 768

# time series encoder
timeseries_input_dim: 76
timeseries_dim_feedforward: 256
timeseries_max_seq_len: 48
timeseries_layers: 3
timeseries_n_heads: 4
timeseries_dropout: 0.1
timeseries_embedding_dim: 76
timeseries_activation: gelu
timeseries_encoder_trainable: false  # Freeze during fine-tuning
timeseries_masking_ratio: 0.15
timeseries_mean_mask_length: 3
timeseries_mask_mode: separate
timeseries_mask_distribution: geometric
impute_strategy: zero
start_time: zero
timestep: 1.0

# Vertex AI distributed training settings
multiprocessing_distributed: true
dist_backend: nccl
ngpus_per_node: 8
world_size: 1
workers: 16

# Vertex AI specific settings
vertex_ai_training: true
save_checkpoints_to_gcs: true
load_checkpoints_from_gcs: true 